{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using Flux, Flux.Optimise\n",
    "using Flux: onehotbatch, onecold\n",
    "using Flux: crossentropy, Momentum\n",
    "using Base.Iterators: partition\n",
    "using Metal\n",
    "using MLDatasets\n",
    "using MLUtils\n",
    "using Images.ImageCore\n",
    "using BenchmarkTools: @btime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×50000 OneHotMatrix(::MtlVector{Int64, Private}) with eltype Bool:\n",
       " ⋅  ⋅  ⋅  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  1  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  1  1\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅     ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  1  1     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Flux.OneHotMatrix(X.targets, 10) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = CIFAR10(:train)\n",
    "labels = Flux.OneHotMatrix(X.targets, 10) |> gpu\n",
    "imgs = X.features |> gpu\n",
    "\n",
    "# Load data to gpu and cpu\n",
    "train_cpu = [(imgs[:,:,:,i], labels[:,i]) for i in partition(1:50000, 1000)] |> cpu\n",
    "train_gpu = [(imgs[:,:,:,i], labels[:,i]) for i in partition(1:50000, 1000)] |> gpu\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((5, 5), 3 => 16, relu),          \u001b[90m# 1_216 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Conv((5, 5), 16 => 8, relu),          \u001b[90m# 3_208 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  MLUtils.flatten,\n",
       "  Dense(200 => 120),                    \u001b[90m# 24_120 parameters\u001b[39m\n",
       "  Dense(120 => 84),                     \u001b[90m# 10_164 parameters\u001b[39m\n",
       "  Dense(84 => 10),                      \u001b[90m# 850 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 10 arrays, \u001b[39m39_558 parameters, 1.758 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define neural networks for both gpu and cpu\n",
    "m_gpu = Chain(\n",
    "  Conv((5,5), 3=>16, relu),\n",
    "  MaxPool((2,2)),\n",
    "  Conv((5,5), 16=>8, relu),\n",
    "  MaxPool((2,2)),\n",
    "  flatten,\n",
    "  Dense(200, 120),\n",
    "  Dense(120, 84),\n",
    "  Dense(84, 10),\n",
    "  softmax) |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((5, 5), 3 => 16, relu),          \u001b[90m# 1_216 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Conv((5, 5), 16 => 8, relu),          \u001b[90m# 3_208 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  MLUtils.flatten,\n",
       "  Dense(200 => 120),                    \u001b[90m# 24_120 parameters\u001b[39m\n",
       "  Dense(120 => 84),                     \u001b[90m# 10_164 parameters\u001b[39m\n",
       "  Dense(84 => 10),                      \u001b[90m# 850 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 10 arrays, \u001b[39m39_558 parameters, 155.852 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_cpu = Chain(\n",
    "  Conv((5,5), 3=>16, relu),\n",
    "  MaxPool((2,2)),\n",
    "  Conv((5,5), 16=>8, relu),\n",
    "  MaxPool((2,2)),\n",
    "  flatten,\n",
    "  Dense(200, 120),\n",
    "  Dense(120, 84),\n",
    "  Dense(84, 10),\n",
    "  softmax) |> cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Momentum(0.01, 0.9, IdDict{Any, Any}())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define loss and optimizer\n",
    "loss_gpu(m, x, y) = sum(crossentropy(m(x), y))\n",
    "opt_gpu = Momentum(0.01)\n",
    "\n",
    "loss_cpu(x, y) = sum(crossentropy(m_cpu(x), y))\n",
    "opt_cpu = Momentum(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set number of training iterations\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompositeException",
     "evalue": "TaskFailedException\n\n    nested task error: TaskFailedException\n    \n        nested task error: Scalar indexing is disallowed.\n        Invocation of getindex resulted in scalar indexing of a GPU array.\n        This is typically caused by calling an iterating implementation of a method.\n        Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n        and therefore should be avoided.\n        \n        If you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\n        to enable scalar iteration globally or for the operations in question.\n        Stacktrace:\n          [1] error(s::String)\n            @ Base ./error.jl:35\n          [2] errorscalar(op::String)\n            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:155\n          [3] _assertscalar(op::String, behavior::GPUArraysCore.ScalarIndexing)\n            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:128\n          [4] assertscalar(op::String)\n            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:116\n          [5] getindex\n            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:50 [inlined]\n          [6] scalar_getindex\n            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:36 [inlined]\n          [7] _getindex\n            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:19 [inlined]\n          [8] getindex\n            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:17 [inlined]\n          [9] getindex\n            @ ./subarray.jl:290 [inlined]\n         [10] im2col!(col::MtlMatrix{Float32, Private}, x::SubArray{Float32, 4, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Int64}, true}, cdims::DenseConvDims{3, 3, 3, 6, 3})\n            @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:238\n         [11] (::NNlib.var\"#640#641\"{MtlArray{Float32, 3, Private}, Float32, Float32, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, MtlArray{Float32, 5, Private}, DenseConvDims{3, 3, 3, 6, 3}, Int64, Int64, Int64, UnitRange{Int64}, Int64})()\n            @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:54\n    Stacktrace:\n     [1] sync_end(c::Channel{Any})\n       @ Base ./task.jl:448\n     [2] macro expansion\n       @ ./task.jl:480 [inlined]\n     [3] conv_im2col!(y::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, x::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, w::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3}; col::MtlArray{Float32, 3, Private}, alpha::Float32, beta::Float32, ntasks::Int64)\n       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:50\n     [4] conv_im2col!(y::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, x::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, w::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3})\n       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:23\n     [5] (::NNlib.var\"#298#302\"{@Kwargs{}, DenseConvDims{3, 3, 3, 6, 3}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, MtlArray{Float32, 5, Private}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}})()\n       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:209",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n",
      "\n",
      "    nested task error: TaskFailedException\n",
      "    \n",
      "        nested task error: Scalar indexing is disallowed.\n",
      "        Invocation of getindex resulted in scalar indexing of a GPU array.\n",
      "        This is typically caused by calling an iterating implementation of a method.\n",
      "        Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n",
      "        and therefore should be avoided.\n",
      "        \n",
      "        If you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\n",
      "        to enable scalar iteration globally or for the operations in question.\n",
      "        Stacktrace:\n",
      "          [1] error(s::String)\n",
      "            @ Base ./error.jl:35\n",
      "          [2] errorscalar(op::String)\n",
      "            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:155\n",
      "          [3] _assertscalar(op::String, behavior::GPUArraysCore.ScalarIndexing)\n",
      "            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:128\n",
      "          [4] assertscalar(op::String)\n",
      "            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:116\n",
      "          [5] getindex\n",
      "            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:50 [inlined]\n",
      "          [6] scalar_getindex\n",
      "            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:36 [inlined]\n",
      "          [7] _getindex\n",
      "            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:19 [inlined]\n",
      "          [8] getindex\n",
      "            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:17 [inlined]\n",
      "          [9] getindex\n",
      "            @ ./subarray.jl:290 [inlined]\n",
      "         [10] im2col!(col::MtlMatrix{Float32, Private}, x::SubArray{Float32, 4, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Int64}, true}, cdims::DenseConvDims{3, 3, 3, 6, 3})\n",
      "            @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:238\n",
      "         [11] (::NNlib.var\"#640#641\"{MtlArray{Float32, 3, Private}, Float32, Float32, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, MtlArray{Float32, 5, Private}, DenseConvDims{3, 3, 3, 6, 3}, Int64, Int64, Int64, UnitRange{Int64}, Int64})()\n",
      "            @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:54\n",
      "    Stacktrace:\n",
      "     [1] sync_end(c::Channel{Any})\n",
      "       @ Base ./task.jl:448\n",
      "     [2] macro expansion\n",
      "       @ ./task.jl:480 [inlined]\n",
      "     [3] conv_im2col!(y::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, x::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, w::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3}; col::MtlArray{Float32, 3, Private}, alpha::Float32, beta::Float32, ntasks::Int64)\n",
      "       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:50\n",
      "     [4] conv_im2col!(y::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, x::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, w::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3})\n",
      "       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:23\n",
      "     [5] (::NNlib.var\"#298#302\"{@Kwargs{}, DenseConvDims{3, 3, 3, 6, 3}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, MtlArray{Float32, 5, Private}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}})()\n",
      "       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:209\n",
      "\n",
      "Stacktrace:\n",
      "  [1] sync_end(c::Channel{Any})\n",
      "    @ Base ./task.jl:448\n",
      "  [2] macro expansion\n",
      "    @ ./task.jl:480 [inlined]\n",
      "  [3] conv!(out::MtlArray{Float32, 5, Private}, in1::MtlArray{Float32, 5, Private}, in2::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3}; kwargs::@Kwargs{})\n",
      "    @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:205\n",
      "  [4] conv!\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:185 [inlined]\n",
      "  [5] conv!(y::MtlArray{Float32, 4, Private}, x::MtlArray{Float32, 4, Private}, w::MtlArray{Float32, 4, Private}, cdims::DenseConvDims{2, 2, 2, 4, 2}; kwargs::@Kwargs{})\n",
      "    @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:145\n",
      "  [6] conv!\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:140 [inlined]\n",
      "  [7] conv(x::MtlArray{Float32, 4, Private}, w::MtlArray{Float32, 4, Private}, cdims::DenseConvDims{2, 2, 2, 4, 2}; kwargs::@Kwargs{})\n",
      "    @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:88\n",
      "  [8] conv\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:83 [inlined]\n",
      "  [9] #rrule#366\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:355 [inlined]\n",
      " [10] rrule\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:345 [inlined]\n",
      " [11] rrule\n",
      "    @ ~/.julia/packages/ChainRulesCore/I1EbV/src/rules.jl:134 [inlined]\n",
      " [12] chain_rrule\n",
      "    @ ~/.julia/packages/Zygote/nsBv0/src/compiler/chainrules.jl:223 [inlined]\n",
      " [13] macro expansion\n",
      "    @ ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0 [inlined]\n",
      " [14] _pullback\n",
      "    @ ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:87 [inlined]\n",
      " [15] Conv\n",
      "    @ ~/.julia/packages/Flux/JKfiV/src/layers/conv.jl:202 [inlined]\n",
      " [16] _pullback(ctx::Zygote.Context{false}, f::Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, args::MtlArray{Float32, 4, Private})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0\n",
      " [17] _applychain\n",
      "    @ ~/.julia/packages/Flux/JKfiV/src/layers/basic.jl:53 [inlined]\n",
      " [18] _pullback(::Zygote.Context{false}, ::typeof(Flux._applychain), ::Tuple{Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, typeof(flatten), Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, typeof(softmax)}, ::MtlArray{Float32, 4, Private})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0\n",
      " [19] Chain\n",
      "    @ ~/.julia/packages/Flux/JKfiV/src/layers/basic.jl:51 [inlined]\n",
      " [20] loss_gpu\n",
      "    @ ~/Documents/PhD/UnboundedBNN/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W3sZmlsZQ==.jl:2 [inlined]\n",
      " [21] #89\n",
      "    @ ~/Documents/PhD/UnboundedBNN/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X25sZmlsZQ==.jl:3 [inlined]\n",
      " [22] _pullback(ctx::Zygote.Context{false}, f::var\"#89#90\"{OneHotArrays.OneHotMatrix{Int64, MtlVector{Int64, Private}}, MtlArray{Float32, 4, Private}}, args::Chain{Tuple{Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, typeof(flatten), Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, typeof(softmax)}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0\n",
      " [23] pullback(f::Function, cx::Zygote.Context{false}, args::Chain{Tuple{Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, typeof(flatten), Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, typeof(softmax)}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface.jl:90\n",
      " [24] pullback\n",
      "    @ ~/.julia/packages/Zygote/nsBv0/src/compiler/interface.jl:88 [inlined]\n",
      " [25] gradient(f::Function, args::Chain{Tuple{Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, typeof(flatten), Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, typeof(softmax)}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface.jl:147\n",
      " [26] top-level scope\n",
      "    @ ~/Documents/PhD/UnboundedBNN/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X25sZmlsZQ==.jl:3"
     ]
    }
   ],
   "source": [
    "for epoch in 1:epochs\n",
    "    for (x, y) in train_gpu\n",
    "        grads = gradient(m -> loss_gpu(m, x, y), m_gpu)\n",
    "        Flux.update!(opt_state, model, grads[1])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompositeException",
     "evalue": "TaskFailedException\n\n    nested task error: TaskFailedException\n    \n        nested task error: Scalar indexing is disallowed.\n        Invocation of getindex resulted in scalar indexing of a GPU array.\n        This is typically caused by calling an iterating implementation of a method.\n        Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n        and therefore should be avoided.\n        \n        If you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\n        to enable scalar iteration globally or for the operations in question.\n        Stacktrace:\n          [1] error(s::String)\n            @ Base ./error.jl:35\n          [2] errorscalar(op::String)\n            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:155\n          [3] _assertscalar(op::String, behavior::GPUArraysCore.ScalarIndexing)\n            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:128\n          [4] assertscalar(op::String)\n            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:116\n          [5] getindex\n            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:50 [inlined]\n          [6] scalar_getindex\n            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:36 [inlined]\n          [7] _getindex\n            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:19 [inlined]\n          [8] getindex\n            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:17 [inlined]\n          [9] getindex\n            @ ./subarray.jl:290 [inlined]\n         [10] im2col!(col::MtlMatrix{Float32, Private}, x::SubArray{Float32, 4, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Int64}, true}, cdims::DenseConvDims{3, 3, 3, 6, 3})\n            @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:238\n         [11] (::NNlib.var\"#640#641\"{MtlArray{Float32, 3, Private}, Float32, Float32, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, MtlArray{Float32, 5, Private}, DenseConvDims{3, 3, 3, 6, 3}, Int64, Int64, Int64, UnitRange{Int64}, Int64})()\n            @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:54\n    Stacktrace:\n     [1] sync_end(c::Channel{Any})\n       @ Base ./task.jl:448\n     [2] macro expansion\n       @ ./task.jl:480 [inlined]\n     [3] conv_im2col!(y::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, x::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, w::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3}; col::MtlArray{Float32, 3, Private}, alpha::Float32, beta::Float32, ntasks::Int64)\n       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:50\n     [4] conv_im2col!(y::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, x::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, w::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3})\n       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:23\n     [5] (::NNlib.var\"#298#302\"{@Kwargs{}, DenseConvDims{3, 3, 3, 6, 3}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, MtlArray{Float32, 5, Private}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}})()\n       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:209",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n",
      "\n",
      "    nested task error: TaskFailedException\n",
      "    \n",
      "        nested task error: Scalar indexing is disallowed.\n",
      "        Invocation of getindex resulted in scalar indexing of a GPU array.\n",
      "        This is typically caused by calling an iterating implementation of a method.\n",
      "        Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n",
      "        and therefore should be avoided.\n",
      "        \n",
      "        If you want to allow scalar iteration, use `allowscalar` or `@allowscalar`\n",
      "        to enable scalar iteration globally or for the operations in question.\n",
      "        Stacktrace:\n",
      "          [1] error(s::String)\n",
      "            @ Base ./error.jl:35\n",
      "          [2] errorscalar(op::String)\n",
      "            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:155\n",
      "          [3] _assertscalar(op::String, behavior::GPUArraysCore.ScalarIndexing)\n",
      "            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:128\n",
      "          [4] assertscalar(op::String)\n",
      "            @ GPUArraysCore ~/.julia/packages/GPUArraysCore/GMsgk/src/GPUArraysCore.jl:116\n",
      "          [5] getindex\n",
      "            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:50 [inlined]\n",
      "          [6] scalar_getindex\n",
      "            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:36 [inlined]\n",
      "          [7] _getindex\n",
      "            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:19 [inlined]\n",
      "          [8] getindex\n",
      "            @ ~/.julia/packages/GPUArrays/bbZD0/src/host/indexing.jl:17 [inlined]\n",
      "          [9] getindex\n",
      "            @ ./subarray.jl:290 [inlined]\n",
      "         [10] im2col!(col::MtlMatrix{Float32, Private}, x::SubArray{Float32, 4, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Int64}, true}, cdims::DenseConvDims{3, 3, 3, 6, 3})\n",
      "            @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:238\n",
      "         [11] (::NNlib.var\"#640#641\"{MtlArray{Float32, 3, Private}, Float32, Float32, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, MtlArray{Float32, 5, Private}, DenseConvDims{3, 3, 3, 6, 3}, Int64, Int64, Int64, UnitRange{Int64}, Int64})()\n",
      "            @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:54\n",
      "    Stacktrace:\n",
      "     [1] sync_end(c::Channel{Any})\n",
      "       @ Base ./task.jl:448\n",
      "     [2] macro expansion\n",
      "       @ ./task.jl:480 [inlined]\n",
      "     [3] conv_im2col!(y::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, x::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, w::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3}; col::MtlArray{Float32, 3, Private}, alpha::Float32, beta::Float32, ntasks::Int64)\n",
      "       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:50\n",
      "     [4] conv_im2col!(y::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, x::SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, w::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3})\n",
      "       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/impl/conv_im2col.jl:23\n",
      "     [5] (::NNlib.var\"#298#302\"{@Kwargs{}, DenseConvDims{3, 3, 3, 6, 3}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}, MtlArray{Float32, 5, Private}, SubArray{Float32, 5, MtlArray{Float32, 5, Private}, Tuple{Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, Base.Slice{Base.OneTo{Int64}}, UnitRange{Int64}, Base.Slice{Base.OneTo{Int64}}}, false}})()\n",
      "       @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:209\n",
      "\n",
      "Stacktrace:\n",
      "  [1] sync_end(c::Channel{Any})\n",
      "    @ Base ./task.jl:448\n",
      "  [2] macro expansion\n",
      "    @ ./task.jl:480 [inlined]\n",
      "  [3] conv!(out::MtlArray{Float32, 5, Private}, in1::MtlArray{Float32, 5, Private}, in2::MtlArray{Float32, 5, Private}, cdims::DenseConvDims{3, 3, 3, 6, 3}; kwargs::@Kwargs{})\n",
      "    @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:205\n",
      "  [4] conv!\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:185 [inlined]\n",
      "  [5] conv!(y::MtlArray{Float32, 4, Private}, x::MtlArray{Float32, 4, Private}, w::MtlArray{Float32, 4, Private}, cdims::DenseConvDims{2, 2, 2, 4, 2}; kwargs::@Kwargs{})\n",
      "    @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:145\n",
      "  [6] conv!\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:140 [inlined]\n",
      "  [7] conv(x::MtlArray{Float32, 4, Private}, w::MtlArray{Float32, 4, Private}, cdims::DenseConvDims{2, 2, 2, 4, 2}; kwargs::@Kwargs{})\n",
      "    @ NNlib ~/.julia/packages/NNlib/PmySZ/src/conv.jl:88\n",
      "  [8] conv\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:83 [inlined]\n",
      "  [9] #rrule#366\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:355 [inlined]\n",
      " [10] rrule\n",
      "    @ ~/.julia/packages/NNlib/PmySZ/src/conv.jl:345 [inlined]\n",
      " [11] rrule\n",
      "    @ ~/.julia/packages/ChainRulesCore/I1EbV/src/rules.jl:134 [inlined]\n",
      " [12] chain_rrule\n",
      "    @ ~/.julia/packages/Zygote/nsBv0/src/compiler/chainrules.jl:223 [inlined]\n",
      " [13] macro expansion\n",
      "    @ ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0 [inlined]\n",
      " [14] _pullback\n",
      "    @ ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:87 [inlined]\n",
      " [15] Conv\n",
      "    @ ~/.julia/packages/Flux/JKfiV/src/layers/conv.jl:202 [inlined]\n",
      " [16] _pullback(ctx::Zygote.Context{true}, f::Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, args::MtlArray{Float32, 4, Private})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0\n",
      " [17] _applychain\n",
      "    @ ~/.julia/packages/Flux/JKfiV/src/layers/basic.jl:53 [inlined]\n",
      " [18] _pullback(::Zygote.Context{true}, ::typeof(Flux._applychain), ::Tuple{Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, typeof(flatten), Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, typeof(softmax)}, ::MtlArray{Float32, 4, Private})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0\n",
      " [19] Chain\n",
      "    @ ~/.julia/packages/Flux/JKfiV/src/layers/basic.jl:51 [inlined]\n",
      " [20] _pullback(ctx::Zygote.Context{true}, f::Chain{Tuple{Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, Conv{2, 4, typeof(relu), MtlArray{Float32, 4, Private}, MtlVector{Float32, Private}}, MaxPool{2, 4}, typeof(flatten), Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, Dense{typeof(identity), MtlMatrix{Float32, Private}, MtlVector{Float32, Private}}, typeof(softmax)}}, args::MtlArray{Float32, 4, Private})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0\n",
      " [21] loss_gpu\n",
      "    @ ~/Documents/PhD/UnboundedBNN/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W3sZmlsZQ==.jl:2 [inlined]\n",
      " [22] _pullback(::Zygote.Context{true}, ::typeof(loss_gpu), ::MtlArray{Float32, 4, Private}, ::OneHotArrays.OneHotMatrix{UInt32, MtlVector{UInt32, Private}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0\n",
      " [23] _apply\n",
      "    @ ./boot.jl:838 [inlined]\n",
      " [24] adjoint\n",
      "    @ ~/.julia/packages/Zygote/nsBv0/src/lib/lib.jl:203 [inlined]\n",
      " [25] _pullback\n",
      "    @ ~/.julia/packages/ZygoteRules/M4xmc/src/adjoint.jl:67 [inlined]\n",
      " [26] #69\n",
      "    @ ~/Documents/PhD/UnboundedBNN/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W4sZmlsZQ==.jl:5 [inlined]\n",
      " [27] _pullback(::Zygote.Context{true}, ::var\"#69#70\"{Tuple{MtlArray{Float32, 4, Private}, OneHotArrays.OneHotMatrix{UInt32, MtlVector{UInt32, Private}}}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface2.jl:0\n",
      " [28] pullback(f::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface.jl:465\n",
      " [29] gradient(f::Function, args::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})\n",
      "    @ Zygote ~/.julia/packages/Zygote/nsBv0/src/compiler/interface.jl:147\n",
      " [30] top-level scope\n",
      "    @ ~/Documents/PhD/UnboundedBNN/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W4sZmlsZQ==.jl:4"
     ]
    }
   ],
   "source": [
    "# GPU benchmark\n",
    "# @btime for epoch = 1:epochs\n",
    "  for d in train_gpu\n",
    "    gs = gradient(Flux.params(m_gpu)) do\n",
    "      l = loss_gpu(d...)\n",
    "    end\n",
    "    update!(opt_gpu, params(m_gpu), gs)\n",
    "  end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU benchmark\n",
    "for epoch = 1:epochs\n",
    "    for d in train_cpu\n",
    "      gs = gradient(Flux.params(m_cpu)) do\n",
    "        l = loss_cpu(d...)\n",
    "      end\n",
    "      update!(opt_cpu, Flux.params(m_cpu), gs)\n",
    "    end\n",
    "  end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
