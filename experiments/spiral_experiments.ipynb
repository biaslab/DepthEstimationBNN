{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using UnboundedBNN, Optimisers, ProgressMeter, Zygote, LinearAlgebra, JLD2, Random, Statistics\n",
    "using UnboundedBNN: TransformedDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crossentropy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function crossentropy(p::Vector, q::Matrix)\n",
    "    mask = p .== 1\n",
    "    return - mapreduce(n -> q[mask[n]+1,n], +, 1:length(p))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function accuracy(x::Matrix, y::Vector, model; nr_evals = 100)\n",
    "    posterior = UnboundedBNN.transform(model.posterior)\n",
    "    lower, upper = UnboundedBNN.support(posterior)\n",
    "    post_pdf = UnboundedBNN.pmf.(Ref(posterior), lower:upper)\n",
    "\n",
    "    logln = zeros(Float64, 2, length(y))\n",
    "    for k in 1:nr_evals\n",
    "        output = model(x)\n",
    "        logln += mapreduce(l -> output[l] .* post_pdf[l], +, 1:length(post_pdf))\n",
    "    end\n",
    "\n",
    "    return mean(getindex.(argmax(logln, dims=1), 1) .== (y .* -1/2 .+ 1.5))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loss(y, x, model; batch_prop = 1.0)\n",
    "    \n",
    "    posterior = UnboundedBNN.transform(model.posterior)\n",
    "    lower, upper = UnboundedBNN.support(posterior)\n",
    "    post_pdf = UnboundedBNN.pmf.(Ref(posterior), lower:upper)\n",
    "\n",
    "    output = model(x)\n",
    "    logln = mapreduce(l -> output[l] .* post_pdf[l], +, 1:length(post_pdf))\n",
    "\n",
    "    kl_poisson = KL_loss(posterior, model.prior)\n",
    "    kl_input = KL_loss(model.input_layer)\n",
    "    kl_hidden = mapreduce(l -> dot(post_pdf[1:l], KL_loss.(model.output_layers[1:l])), +, 1:length(post_pdf))\n",
    "    kl_output = mapreduce(l -> post_pdf[l] * KL_loss(model.output_layers[l]), +, 1:length(post_pdf))\n",
    "    kl_total = kl_poisson + kl_input + kl_output + kl_hidden\n",
    "\n",
    "    return crossentropy(y, logln) + batch_prop * kl_total\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function create_model(dims::Pair, dimmid; max_layers=30)\n",
    "\n",
    "    expansion_layer = Chain(LinearBBB(dims[1] => dimmid), LeakyReLU())\n",
    "    intermediate_layer = ntuple(_ -> Chain(LinearBBB(dimmid => dimmid), LeakyReLU()), max_layers)\n",
    "    output_layer = ntuple(_ -> Chain(LinearBBB(dimmid => dims[2]), Softmax(dims[2])), max_layers)\n",
    "\n",
    "    prior = discretize(H() * Normal(0.0f0 , 2.0f0))\n",
    "    posterior = TransformedDistribution(\n",
    "        SafeNormal([0.0f0], [invsoftplus(2.0f0)]), \n",
    "        (\n",
    "            x -> H() * x,\n",
    "            x -> truncate_to_quantiles(x, 0.025f0, 0.975f0),\n",
    "            x -> expand_truncation_to_ints(x),\n",
    "            x -> discretize(x)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return Unbounded(\n",
    "        expansion_layer,\n",
    "        intermediate_layer,\n",
    "        output_layer, \n",
    "        prior, \n",
    "        posterior\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_optimiser (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function create_optimiser(model; lr=0.005f0)\n",
    "    opt = Optimisers.setup(Adam(), model)\n",
    "    Optimisers.adjust!(opt, lr)\n",
    "    Optimisers.adjust!(opt.posterior, lr/10)\n",
    "    return opt\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_experiment (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function run_experiment(folder, ω, dimmid; epochs=5000, batch_size=256, lr=0.005f0, max_layers=30, N=8192, rng=Random.default_rng())\n",
    "    \n",
    "    mkpath(folder)\n",
    "\n",
    "    # loop over dimensions\n",
    "    for dim in dimmid\n",
    "\n",
    "        p = ProgressMeter.Progress(length(ω))\n",
    "\n",
    "        # loop over difficulties\n",
    "        Threads.@threads for ωi in ω\n",
    "\n",
    "            # generate data\n",
    "            Random.seed!(ωi)\n",
    "            x_train, y_train = generate_spiral(N, ωi)\n",
    "            x_val,   y_val   = generate_spiral(N, ωi)\n",
    "            x_test,  y_test  = generate_spiral(N, ωi)\n",
    "\n",
    "            # create model and optimiser\n",
    "            model = create_model(2 => 2, dim, max_layers=max_layers)\n",
    "            opt = create_optimiser(model, lr=lr)\n",
    "            \n",
    "            loss_train = zeros(epochs)\n",
    "            loss_val   = zeros(epochs)\n",
    "            loss_test  = zeros(epochs)\n",
    "            best_val = Inf\n",
    "            best_model = nothing\n",
    "\n",
    "            for e in 1:epochs\n",
    "                for n in Iterators.partition(randperm(rng, N), batch_size)\n",
    "                    _, gs = Zygote.withgradient(m -> loss(y_train[n], x_train[:,n], m; batch_prop = length(n)/N), model)\n",
    "                    opt, model = Optimisers.update!(opt, model, gs[1])\n",
    "                end\n",
    "                loss_train[e] = loss(y_train, x_train, model)\n",
    "                loss_val[e] = loss(y_val, x_val, model)\n",
    "                loss_test[e] = loss(y_test, x_test, model)\n",
    "\n",
    "                if loss_val[e] < best_val\n",
    "                    best_val = loss_val[e]\n",
    "                    best_model = model\n",
    "                end\n",
    "\n",
    "            end\n",
    "\n",
    "            #save results\n",
    "            jldopen(\"$folder/dim_$(dim)_omega_$(ωi).jld2\", \"w\") do file\n",
    "                file[\"data/x_train\"] = x_train\n",
    "                file[\"data/y_train\"] = y_train\n",
    "                file[\"data/x_val\"] = x_val\n",
    "                file[\"data/y_val\"] = y_val\n",
    "                file[\"data/x_test\"] = x_test\n",
    "                file[\"data/y_test\"] = y_test\n",
    "                file[\"model\"] = best_model\n",
    "                file[\"results/loss_train\"] = loss_train\n",
    "                file[\"results/loss_val\"] = loss_val\n",
    "                file[\"results/loss_test\"] = loss_test\n",
    "                file[\"results/accuracy_train\"] = accuracy(x_train, y_train, best_model)\n",
    "                file[\"results/accuracy_val\"] = accuracy(x_val, y_val, best_model)\n",
    "                file[\"results/accuracy_test\"] = accuracy(x_test, y_test, best_model)\n",
    "            end\n",
    "\n",
    "            ProgressMeter.next!(p)\n",
    "\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:17:01\u001b[39m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\"data/spiral\", 1:20, (4, 8, 16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
